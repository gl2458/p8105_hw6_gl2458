---
title: "p8105_hw6_gl2458"
author: "Rachel Lee"
data: "01/08/2020"
output: gihub_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(mgcv)
library(purrr)
library(mlbench)
library(ggplot2)
library(broom)
library(patchwork)
theme_set(theme_bw() + theme(legend.position = "bottom"))
```

Problem 1: 
a) Import and clean childbirth dataset.Convert numeric to factor and check for missing data. 

```{r p1_data_import_tidying, message=FALSE}
child_data = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(babysex = as.factor(babysex))%>% 
  mutate(frace = as.factor(frace))%>% 
  mutate(mrace = as.factor(mrace))%>% 
  mutate(malform = as.factor(malform)) %>% 
  mutate(parity = as.factor(parity)) %>% 
  select(-pnumlbw, -pnumsga) %>%  
  select(bwt, babysex, everything())
```

By mutating, babysex, father's race, mother's race, presence of malformations, and parity are converted to factors from numeric. Previous number of low birth weight babies (pnumlbw) and number of prior small for gestational age babies (pnumsga) are excluded from the data.

b) Propose a regression model

Regression model using *stepwise regression* with *backward elimination*. Predictor selection is performed by sequentially eliminating predictors that lower Akaike information criterion. 

```{r p1_modelselection, results=FALSE}
fit_mlr_child_bwt = lm(bwt ~ ., data = child_data)
backward_elim_child_bwt_predictors =
  step(fit_mlr_child_bwt, direction = "backward") %>% 
  broom::tidy() %>% 
  knitr::kable()
# stepwise regression with backward elimination
```

The selected regression model includes the following predictors: 
`r backward_elim_child_bwt_predictors %>% t() %>% knitr::kable()`

Proposed regression model: 
```{r p1_new_model}
new_mlr_child_bwt = 
  lm(bwt ~ parity + fincome + babysex + mheight + ppwt + gaweeks + smoken + delwt + mrace + blength + bhead, data = child_data)
new_mlr_child_bwt %>% 
  broom::tidy()
```

Plotting model residuals against fitted model with add_predictions and add_residuals.

```{r p1_model_prediction_vs_residuals}
child_data %>% 
  add_predictions(new_mlr_child_bwt) %>% 
  add_residuals(new_mlr_child_bwt) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values", 
    y = "Residuals"
  )
```


### Comparing the selected model to following two models: 

MLR_1 : Main effects only (predictors - length at birth and gestational age)

MLR_2 : Three way interactions (predictors - head circumference, length, sex, and all interactions)

Cross validation is carried out in the below code chunk. Moreover, the spread of *root mean squares* of the three models is plotted.

```{r p1_model_comparisons}
set.seed(1)
fit_mlr_1 = lm(bwt ~ blength + gaweeks, data = child_data)
fit_mlr_2 = lm(bwt ~ bhead*blength*babysex, data = child_data) 
# multiple regression with interaction
xval_df = 
  crossv_mc(child_data, n = 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) 
xval_df = xval_df %>% 
  mutate(proposed_mlr  = map(train, ~lm(bwt ~ parity + fincome + babysex + mheight + ppwt + gaweeks + smoken + delwt + mrace + blength + bhead, data = child_data)),
         mlr_1 = map(train, ~lm(bwt ~ blength + gaweeks, data = child_data)),
         mlr_2 = map(train, ~lm(bwt ~ bhead*blength*babysex, data = child_data))
  ) %>% 
  mutate(rmse_proposed  = map2_dbl(proposed_mlr,  test, ~rmse(model = .x, data = .y)),
         rmse_mlr_1 = map2_dbl(mlr_1, test, ~rmse(model = .x, data = .y)),
         rmse_mlr_2 = map2_dbl(mlr_2, test, ~rmse(model = .x, data = .y))
  )
xval_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(), 
    names_to = "model",
    values_to = "rmse", 
    names_prefix = "rmse_") %>%  
  mutate(model =   fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin() + 
  labs(
    title = "Comparison of the selected model to two alternative models",
    x = "Models", 
    y = "Root mean squares"
  )
```

The selected model from backward elimination stepwise regression has the smallest room mean square spread which indicates. This proves that the model selection methods was approriate. The plots of the two alternative models suggest that the model with three-way interactions is a better fit than the model with only main effects. 




# Problem 2

Importing data
```{r p2_impor_data, message= FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


Create results  

```{r p2_create_results}
results = weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy),
    glance = map(models, broom::glance)) %>% 
  select(results, glance, .id) %>% 
  unnest(results) %>% 
  pivot_wider( 
    names_from = term,
    values_from = c(estimate, std.error, glance),
    id_cols = .id, 
    ) %>%
  janitor::clean_names() %>%
  mutate(
    log_b0_b1 = log(estimate_intercept * estimate_tmin)
  ) %>%
  unnest(c(glance_intercept))
```

Below table shows the 95% confidence interval for R-squared. 
```{r p2_95CI_rsquared}
results %>% 
  pull(r.squared) %>% 
  quantile(c(0.025, 0.975)) %>% 
  knitr::kable(col.names = "R squared")
```








